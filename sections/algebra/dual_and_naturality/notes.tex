\section{Duality and Natural Transformations}

Eilenberg and Maclane's classic paper introduces the concept of generalized naturality by discussing 
the classic example of how an isomorphism between a vector space \(V\) and its dual \(V^*\) is dependent on
the basis you choose to construct the isomorphism. They mention that considering the naturality of this 
"...clearly involves a simultaneous consideration of all spaces \(L\) and all transformations \(\lambda\)
connecting them."

I would like to comment on two points that I think could use more discussion:
\begin{enumerate}
\item Why do we consider transformations when the original concept involves basis?
\item Why must we consider the standard contravariant functor?
\end{enumerate}

For point (1), it is enough to simply observe that a basis \(\{\beta_i\}\) for an \(n\)-dimensional vector space \(V\) is
equivalent to a linear isomorphism \(C_\beta: \mathbb R^n \to V\). Therefore our study of dependence of basis
leads us to consider such isomorphisms and to expand our consideration to more general maps.

Point (2) is a little more involved. For this we should consider what it means to be "independent of basis." We
can think of this as being that the transformation "looks the same" in every basis. What do we precisely mean
by how a transformation "looks" for a given basis? We can think of this as how the transformation acts
on the coordinates of the basis. 

For a one-form \(\omega \in V^*\), this is given by the pull-back by of the linear transformation
\(C_\beta: \mathbb R^n  \to V\) that represents the basis \(\{\beta_i\}\). Therefore, we are lead to
consider duality as a contravariant functor.  

Now, if we don't consider naturality, and we consider any map \(T: V \to V^*\), then we are lead to the following
diagram:
\begin{figure}[h]
\centering
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
{ \mathbb R^* & V^* \\
  \mathbb R & V \\ 
};
\path[-stealth]
    (m-1-2) edge node [above] {\(C_\beta^*\)} (m-1-1)
    (m-2-2) edge node [right] {\(T\)} (m-1-2)
    (m-2-1) edge node [below] {\(C_\beta\)} (m-2-2)
            edge node [left] {\(S_\beta\)} (m-1-1);
\end{tikzpicture}
\end{figure}
where \(S_\beta : \mathbb R \to \mathbb R^*\) is the map induced by \(C_\beta\), \(T\), and \(C_\beta^*\).

Then what it means to be "independent of basis" is that this map \(T_\beta\) is actually indepent of \(\beta\).
So we have that there is a map \(S = S_\beta\) for all bases \(\{\beta_i\}\); we have the diagram: 
\begin{figure}[h]
\centering
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
{ \mathbb R^* & V^* \\
  \mathbb R & V \\ 
};
\path[-stealth]
    (m-1-2) edge node [above] {\(C_\beta^*\)} (m-1-1)
    (m-2-2) edge node [right] {\(T\)} (m-1-2)
    (m-2-1) edge node [below] {\(C_\beta\)} (m-2-2)
            edge node [left] {\(S\)} (m-1-1);
\end{tikzpicture}
\end{figure}

